{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Downloads SQuAD train and dev sets, preprocesses and writes tokenized versions to file'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Downloads SQuAD train and dev sets, preprocesses and writes tokenized versions to file\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import argparse\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from six.moves.urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tqdm** is a python library which is very helpful to show the progress of loops.\n",
    "**six** is  a python library which makes the code compatible with pyhton2 as well as python3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo-random number generators work by performing some operation on a value. Generally this value is the previous number generated by the generator. However, the first time you use the generator, there is no previous value.\n",
    "\n",
    "Seeding a pseudo-random number generator gives it its first \"previous\" value. Each seed value will correspond to a sequence of generated values for a given random number generator. That is, if you provide the same seed twice, you get the same sequence of numbers twice.\n",
    "\n",
    "Generally, you want to seed your random number generator with some value that will change each execution of the program. For instance, the current time is a frequently-used seed. The reason why this doesn't happen automatically is so that if you want, you can provide a specific seed to get a known sequence of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUAD_BASE_URL = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_args():\n",
    "    \"\"\"Sets up an argument parser and return it\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data_dir\", required=True)\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(out_file, line):\n",
    "    \"\"\"Take a line and file as input, encdes the line to utf-8 and then writes that line to the file\"\"\"\n",
    "    out_file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_from_json(filename):\n",
    "    \"\"\"Loads JSON data from filename and returns\"\"\"\n",
    "    with open(filename) as data_file:\n",
    "        data = json.load(data_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sequence):\n",
    "    \"\"\"Tokenizes the input sequence using nltk's word_tokenize function, replaces two single quotes with a double quote\"\"\"\n",
    "    tokens = [token.replace(\"``\", '\"').replace(\"''\", '\"').lower()\n",
    "              for token in nltk.word_tokenize(sequence)]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word_tokenize returns each and every token including \",\", \"'\", \"?\", \".\", etc.. i.e. everything except a space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_examples(dataset):\n",
    "    \"\"\"Returns the total number of (context, question, answer) triples, given the data loaded from the SQuAD json file\"\"\"\n",
    "    total = 0\n",
    "    for article in dataset['data']:\n",
    "        for para in article['paragraphs']:\n",
    "            total += len(para['qas'])\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporthook(t):\n",
    "    \"\"\"https://github.com/tqdm/tqdm\"\"\"\n",
    "    last_b = [0]\n",
    "\n",
    "    def inner(b=1, bsize=1, tsize=None):\n",
    "        \"\"\"\n",
    "        b: int, optional\n",
    "            Number of blocks just transferred [default: 1].\n",
    "        bsize: int, optional\n",
    "            Size of each block (in tqdm units) [default: 1].\n",
    "        tsize: int, optional\n",
    "            Total size (in tqdm units). If [default: None] remains unchanged.\n",
    "        \"\"\"\n",
    "        if tsize is not None:\n",
    "            t.total = tsize\n",
    "        t.update((b - last_b[0]) * bsize)\n",
    "        last_b[0] = b\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns a function which provides live updates of percentage file download at command prompt. The function isn't built-in and hence, needs to be coded by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download(url, filename, prefix, num_bytes=None):\n",
    "    \"\"\"Takes an URL, a filename, and the expected bytes, download the contents and returns the filename. num_bytes=None disables the file size check.\"\"\"\n",
    "    local_filename = None\n",
    "    if not os.path.exists(os.path.join(prefix, filename)):\n",
    "        try:\n",
    "            print(\"Downloading file {}...\".format(url + filename))\n",
    "            with tqdm(unit='B', unit_scale=True, miniters=1, desc=filename) as t:\n",
    "                local_filename, _ = urlretrieve(\n",
    "                    url + filename, os.path.join(prefix, filename), reporthook=reporthook(t))\n",
    "        except AttributeError as e:\n",
    "            print(\"An error occurred when downloading the file! Please get the dataset using a browser.\")\n",
    "            raise e\n",
    "    # We have a downloaded file\n",
    "    # Check the stats and make sure they are ok\n",
    "    file_stats = os.stat(os.path.join(prefix, filename))\n",
    "    if num_bytes is None or file_stats.st_size == num_bytes:\n",
    "        print(\"File {} successfully loaded\".format(filename))\n",
    "    else:\n",
    "        raise Exception(\n",
    "            \"Unexpected dataset size. Please get the dataset using a browser.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**urlretrive**: Return a tuple (filename, headers) where filename is the local file name under which the object can be found, and headers is whatever the info() method of the object returned by urlopen() returned (for a remote object, possibly cached).\n",
    "\n",
    "It doesn't return the bytes of the file. The point of urlretrieve is that it handles writing to a file for you, and returns the filename it was written to (which will generally be the same thing as your second argument to the function if you provided one).\n",
    "\n",
    "**_ as a variable that catches what function returns**: _ has 3 main conventional uses in Python:\n",
    "- To hold the result of the last executed expression(/statement) in an interactive interpreter session. This precedent was set by the standard CPython interpreter, and other interpreters have followed suit\n",
    "- For translation lookup in i18n (see the gettext documentation for example), as in code like: raise forms.ValidationError(_(\"Please enter a correct username\"))\n",
    "- As a general purpose \"throwaway\" variable name to indicate that part of a function result is being deliberately ignored, as in code like: label, has_label, _ = text.partition(':')\n",
    "\n",
    "**os.stat()**: The method stat() performs a stat system call on the given path.\n",
    "\n",
    "Here is the list of members of stat structure returned −\n",
    "\n",
    "    st_mode − protection bits.\n",
    "    st_ino − inode number.\n",
    "    st_dev − device.\n",
    "    st_nlink − number of hard links.\n",
    "    st_uid − user id of owner.\n",
    "    st_gid − group id of owner.\n",
    "    st_size − size of file, in bytes.\n",
    "    st_atime − time of most recent access.\n",
    "    st_mtime − time of most recent content modification.\n",
    "    st_ctime − time of most recent metadata change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_word_loc_mapping(context, context_tokens):\n",
    "    \"\"\"\n",
    "    Return a mapping that maps from character locations to the corresponding token locations.\n",
    "    If we're unable to complete the mapping e.g. because of special characters, we return None.\n",
    "\n",
    "    Inputs:\n",
    "      context: string (unicode)\n",
    "      context_tokens: list of strings (unicode)\n",
    "\n",
    "    Returns:\n",
    "      mapping: dictionary from ints (character locations) to (token, token_idx) pairs\n",
    "        Only ints corresponding to non-space character locations are in the keys\n",
    "        e.g. if context = \"hello world\" and context_tokens = [\"hello\", \"world\"] then\n",
    "        0,1,2,3,4 are mapped to (\"hello\", 0) and 6,7,8,9,10 are mapped to (\"world\", 1)\n",
    "    \"\"\"\n",
    "    acc = ''  # accumulator\n",
    "    current_token_idx = 0  # current word loc\n",
    "    mapping = dict()\n",
    "\n",
    "    # step through original characters\n",
    "    for char_idx, char in enumerate(context):\n",
    "        if char != u' ' and char != u'\\n':  # if it's not a space:\n",
    "            acc += char  # add to accumulator\n",
    "            context_token = context_tokens[current_token_idx]  # current word token\n",
    "            if acc == context_token:  # if the accumulator now matches the current word token\n",
    "                # char loc of the start of this word\n",
    "                syn_start = char_idx - len(acc) + 1\n",
    "                for char_loc in range(syn_start, char_idx + 1):\n",
    "                    mapping[char_loc] = (acc, current_token_idx)  # add to mapping\n",
    "                acc = ''  # reset accumulator\n",
    "                current_token_idx += 1\n",
    "\n",
    "    if current_token_idx != len(context_tokens):\n",
    "        return None\n",
    "    else:\n",
    "        return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_write(dataset, tier, out_dir):\n",
    "    \"\"\"Reads the dataset, extracts context, question, answer, tokenizes them, and calculates answer span in terms of token indices.\n",
    "    Note: due to tokenization issues, and the fact that the original answer spans are given in terms of characters, some examples are discarded because we cannot get a clean span in terms of tokens.\n",
    "\n",
    "    This function produces the {train/dev}.{context/question/answer/span} files.\n",
    "\n",
    "    Inputs:\n",
    "      dataset: read from JSON\n",
    "      tier: string (\"train\" or \"dev\")\n",
    "      out_dir: directory to write the preprocessed files\n",
    "    Returns:\n",
    "      the number of (context, question, answer) triples written to file by the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    num_exs = 0  # number of examples written to file\n",
    "    num_mappingprob, num_tokenprob, num_spanalignprob = 0, 0, 0\n",
    "    examples = []\n",
    "\n",
    "    for articles_id in tqdm(range(len(dataset['data'])), desc=\"Preprocessing {}\".format(tier)):\n",
    "\n",
    "        article_paragraphs = dataset['data'][articles_id]['paragraphs']\n",
    "        for pid in range(len(article_paragraphs)):\n",
    "\n",
    "            context = article_paragraphs[pid]['context']  # string\n",
    "\n",
    "            # The following replacements are suggested in the paper\n",
    "            # BidAF (Seo et al., 2016)\n",
    "            context = context.replace(\"''\", '\" ')\n",
    "            context = context.replace(\"``\", '\" ')\n",
    "\n",
    "            context_tokens = tokenize(context)  # list of strings (lowercase)\n",
    "            context = context.lower()\n",
    "\n",
    "            qas = article_paragraphs[pid]['qas']  # list of questions\n",
    "\n",
    "            # charloc2wordloc maps the character location (int) of a context token to a pair giving (word (string), word loc (int)) of that token\n",
    "            charloc2wordloc = get_char_word_loc_mapping(\n",
    "                context, context_tokens)\n",
    "\n",
    "            if charloc2wordloc is None:  # there was a problem\n",
    "                num_mappingprob += len(qas)\n",
    "                continue  # skip this context example\n",
    "\n",
    "            # for each question, process the question and answer and write to file\n",
    "            for qn in qas:\n",
    "\n",
    "                # read the question text and tokenize\n",
    "                question = qn['question']  # string\n",
    "                question_tokens = tokenize(question)  # list of strings\n",
    "\n",
    "                # of the three answers, just take the first\n",
    "                # get the answer text\n",
    "                ans_text = qn['answers'][0]['text'].lower()\n",
    "                # answer start loc (character count)\n",
    "                ans_start_charloc = qn['answers'][0]['answer_start']\n",
    "                # answer end loc (character count) (exclusive)\n",
    "                ans_end_charloc = ans_start_charloc + len(ans_text)\n",
    "\n",
    "                # Check that the provided character spans match the provided answer text\n",
    "                if context[ans_start_charloc:ans_end_charloc] != ans_text:\n",
    "                    # Sometimes this is misaligned, mostly because \"narrow builds\" of Python 2 interpret certain Unicode characters to have length 2 https://stackoverflow.com/questions/29109944/python-returns-length-of-2-for-single-unicode-character-string\n",
    "                    # We should upgrade to Python 3 next year!\n",
    "                    num_spanalignprob += 1\n",
    "                    continue\n",
    "\n",
    "                # get word locs for answer start and end (inclusive)\n",
    "                # answer start word loc\n",
    "                ans_start_wordloc = charloc2wordloc[ans_start_charloc][1]\n",
    "                # answer end word loc\n",
    "                ans_end_wordloc = charloc2wordloc[ans_end_charloc - 1][1]\n",
    "                assert ans_start_wordloc <= ans_end_wordloc\n",
    "\n",
    "                # Check retrieved answer tokens match the provided answer text.\n",
    "                # Sometimes they won't match, e.g. if the context contains the phrase \"fifth-generation\"\n",
    "                # and the answer character span is around \"generation\",\n",
    "                # but the tokenizer regards \"fifth-generation\" as a single token.\n",
    "                # Then ans_tokens has \"fifth-generation\" but the ans_text is \"generation\", which doesn't match.\n",
    "                ans_tokens = context_tokens[ans_start_wordloc:ans_end_wordloc + 1]\n",
    "                if \"\".join(ans_tokens) != \"\".join(ans_text.split()):\n",
    "                    num_tokenprob += 1\n",
    "                    continue  # skip this question/answer pair\n",
    "\n",
    "                examples.append((' '.join(context_tokens), ' '.join(question_tokens), ' '.join(\n",
    "                    ans_tokens), ' '.join([str(ans_start_wordloc), str(ans_end_wordloc)])))\n",
    "\n",
    "                num_exs += 1\n",
    "\n",
    "    print(\"Number of (context, question, answer) triples discarded due to char -> token mapping problems: \", num_mappingprob)\n",
    "    print(\"Number of (context, question, answer) triples discarded because character-based answer span is unaligned with tokenization: \", num_tokenprob)\n",
    "    print(\"Number of (context, question, answer) triples discarded due character span alignment problems (usually Unicode problems): \", num_spanalignprob)\n",
    "    print(\"Processed %i examples of total %i\\n\" % (num_exs, num_exs + num_mappingprob + num_tokenprob + num_spanalignprob))\n",
    "\n",
    "    # shuffle examples\n",
    "    indices = list(range(len(examples)))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    with open(os.path.join(out_dir, tier + '.context'), 'w', encoding='utf-8') as context_file,  \\\n",
    "            open(os.path.join(out_dir, tier + '.question'), 'w', encoding='utf-8') as question_file,\\\n",
    "            open(os.path.join(out_dir, tier + '.answer'), 'w', encoding='utf-8') as ans_text_file, \\\n",
    "            open(os.path.join(out_dir, tier + '.span'), 'w', encoding='utf-8') as span_file:\n",
    "\n",
    "        for i in indices:\n",
    "            (context, question, answer, answer_span) = examples[i]\n",
    "\n",
    "            # write tokenized data to file\n",
    "            write_to_file(context_file, context)\n",
    "            write_to_file(question_file, question)\n",
    "            write_to_file(ans_text_file, answer)\n",
    "            write_to_file(span_file, answer_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        args = setup_args()\n",
    "        data_dir = args.data_dir\n",
    "    except:\n",
    "        data_dir = os.path.join('data', 'squad')\n",
    "\n",
    "    print(\"Will download SQuAD datasets to {}\".format(data_dir))\n",
    "    print(\"Will put preprocessed SQuAD datasets in {}\".format(data_dir))\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    train_filename = \"train-v1.1.json\"\n",
    "    dev_filename = \"dev-v1.1.json\"\n",
    "\n",
    "    # download train set\n",
    "    maybe_download(SQUAD_BASE_URL, train_filename, data_dir, 30288272)\n",
    "\n",
    "    # read train set\n",
    "    train_data = data_from_json(os.path.join(data_dir, train_filename))\n",
    "    print(\"Train data has %i examples total\" % total_examples(train_data))\n",
    "\n",
    "    # preprocess train set and write to file\n",
    "    preprocess_and_write(train_data, 'train', data_dir)\n",
    "\n",
    "    # download dev set\n",
    "    maybe_download(SQUAD_BASE_URL, dev_filename, data_dir, 4854279)\n",
    "\n",
    "    # read dev set\n",
    "    dev_data = data_from_json(os.path.join(data_dir, dev_filename))\n",
    "    print(\"Dev data has %i examples total\" % total_examples(dev_data))\n",
    "\n",
    "    # preprocess dev set and write to file\n",
    "    preprocess_and_write(dev_data, 'dev', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --data_dir DATA_DIR\n",
      "ipykernel_launcher.py: error: the following arguments are required: --data_dir\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will download SQuAD datasets to squad\n",
      "Will put preprocessed SQuAD datasets in squad\n",
      "File train-v1.1.json successfully loaded\n",
      "Train data has 87599 examples total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing train:  74%|███████████████████████████████████████████▋               | 327/442 [00:39<00:13,  8.25it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
